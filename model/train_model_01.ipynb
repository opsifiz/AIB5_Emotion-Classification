{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets scikit-learn evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T17:05:29.716118Z",
     "iopub.status.busy": "2025-06-05T17:05:29.715437Z",
     "iopub.status.idle": "2025-06-05T17:05:30.026236Z",
     "shell.execute_reply": "2025-06-05T17:05:30.025668Z",
     "shell.execute_reply.started": "2025-06-05T17:05:29.716079Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T17:05:32.688951Z",
     "iopub.status.busy": "2025-06-05T17:05:32.688283Z",
     "iopub.status.idle": "2025-06-05T17:05:33.785985Z",
     "shell.execute_reply": "2025-06-05T17:05:33.785296Z",
     "shell.execute_reply.started": "2025-06-05T17:05:32.688921Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>status</th>\n",
       "      <th>from</th>\n",
       "      <th>translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>df1</td>\n",
       "      <td>โอ้พระเจ้า!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble sleeping confused mind restless heart ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>df1</td>\n",
       "      <td>นอนไม่หลับ วุ่นวายใจ กระวนกระวายใจ ทุกอย่างดูผ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all wrong back off dear forward doubt stay in ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>df1</td>\n",
       "      <td>ทุกอย่างไม่ถูกต้อง ถอยไปเถอะ อย่าก้าวไปข้างหน้...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have shifted my focus to something else but ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>df1</td>\n",
       "      <td>ฉันพยายามเบนความสนใจไปเรื่องอื่นแล้ว แต่ก็ยังก...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am restless and restless it is been a month ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>df1</td>\n",
       "      <td>ฉันกระวนกระวายใจมาก มันเป็นแบบนี้มาเป็นเดือนแล...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104995</th>\n",
       "      <td>low testosterone after discontinuing rispredon...</td>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>df3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104996</th>\n",
       "      <td>how did you finally accept your diagnosis i am...</td>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>df3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104997</th>\n",
       "      <td>constantly feel like i am in a competition wit...</td>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>df3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104998</th>\n",
       "      <td>has anyone switched over to an entirely differ...</td>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>df3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104999</th>\n",
       "      <td>has anyone experienced anything like this psyc...</td>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>df3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text         status from  \\\n",
       "0                                              oh my gosh        Anxiety  df1   \n",
       "1       trouble sleeping confused mind restless heart ...        Anxiety  df1   \n",
       "2       all wrong back off dear forward doubt stay in ...        Anxiety  df1   \n",
       "3       i have shifted my focus to something else but ...        Anxiety  df1   \n",
       "4       i am restless and restless it is been a month ...        Anxiety  df1   \n",
       "...                                                   ...            ...  ...   \n",
       "104995  low testosterone after discontinuing rispredon...  schizophrenia  df3   \n",
       "104996  how did you finally accept your diagnosis i am...  schizophrenia  df3   \n",
       "104997  constantly feel like i am in a competition wit...  schizophrenia  df3   \n",
       "104998  has anyone switched over to an entirely differ...  schizophrenia  df3   \n",
       "104999  has anyone experienced anything like this psyc...  schizophrenia  df3   \n",
       "\n",
       "                                               translated  \n",
       "0                                             โอ้พระเจ้า!  \n",
       "1       นอนไม่หลับ วุ่นวายใจ กระวนกระวายใจ ทุกอย่างดูผ...  \n",
       "2       ทุกอย่างไม่ถูกต้อง ถอยไปเถอะ อย่าก้าวไปข้างหน้...  \n",
       "3       ฉันพยายามเบนความสนใจไปเรื่องอื่นแล้ว แต่ก็ยังก...  \n",
       "4       ฉันกระวนกระวายใจมาก มันเป็นแบบนี้มาเป็นเดือนแล...  \n",
       "...                                                   ...  \n",
       "104995                                                  -  \n",
       "104996                                                  -  \n",
       "104997                                                  -  \n",
       "104998                                                  -  \n",
       "104999                                                  -  \n",
       "\n",
       "[105000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/dataset/train_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T17:05:35.156080Z",
     "iopub.status.busy": "2025-06-05T17:05:35.155860Z",
     "iopub.status.idle": "2025-06-05T17:05:35.611254Z",
     "shell.execute_reply": "2025-06-05T17:05:35.610519Z",
     "shell.execute_reply.started": "2025-06-05T17:05:35.156062Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Anxiety': 0, 'BPD': 1, 'Normal': 2, 'bipolar': 3, 'depression': 4, 'mentalillness': 5, 'schizophrenia': 6}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load and encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['status'])\n",
    "\n",
    "# Get label names and mapping\n",
    "label_names = label_encoder.classes_\n",
    "num_labels = len(label_names)\n",
    "\n",
    "# Optional: Check label mappings\n",
    "label_mapping = dict(zip(label_names, range(num_labels)))\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T17:05:37.991948Z",
     "iopub.status.busy": "2025-06-05T17:05:37.991217Z",
     "iopub.status.idle": "2025-06-05T17:05:39.262476Z",
     "shell.execute_reply": "2025-06-05T17:05:39.261947Z",
     "shell.execute_reply.started": "2025-06-05T17:05:37.991924Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert to Hugging Face Dataset format\n",
    "dataset = Dataset.from_pandas(df[['text', 'label']])\n",
    "dataset = dataset.train_test_split(test_size=0.2)  # Split into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"  # Use bart-base for faster fine-tuning than bart-large-mnli\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T17:06:29.278037Z",
     "iopub.status.busy": "2025-06-05T17:06:29.277082Z",
     "iopub.status.idle": "2025-06-05T17:06:30.161685Z",
     "shell.execute_reply": "2025-06-05T17:06:30.161125Z",
     "shell.execute_reply.started": "2025-06-05T17:06:29.278010Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_179923/1637027611.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.006,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T17:06:36.006886Z",
     "iopub.status.busy": "2025-06-05T17:06:36.006525Z",
     "iopub.status.idle": "2025-06-05T18:23:55.957505Z",
     "shell.execute_reply": "2025-06-05T18:23:55.956740Z",
     "shell.execute_reply.started": "2025-06-05T17:06:36.006860Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15750' max='15750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15750/15750 1:17:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.165200</td>\n",
       "      <td>1.039024</td>\n",
       "      <td>0.643619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.004300</td>\n",
       "      <td>0.981171</td>\n",
       "      <td>0.667667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.914500</td>\n",
       "      <td>0.934789</td>\n",
       "      <td>0.674667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.884200</td>\n",
       "      <td>0.915524</td>\n",
       "      <td>0.682952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.979900</td>\n",
       "      <td>0.880412</td>\n",
       "      <td>0.696190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.677700</td>\n",
       "      <td>0.884442</td>\n",
       "      <td>0.694952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.786500</td>\n",
       "      <td>0.862642</td>\n",
       "      <td>0.701476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.818400</td>\n",
       "      <td>0.846433</td>\n",
       "      <td>0.707905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.778500</td>\n",
       "      <td>0.847287</td>\n",
       "      <td>0.703667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.827995</td>\n",
       "      <td>0.712190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.752500</td>\n",
       "      <td>0.841517</td>\n",
       "      <td>0.713143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.575900</td>\n",
       "      <td>0.839431</td>\n",
       "      <td>0.719048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.666300</td>\n",
       "      <td>0.834017</td>\n",
       "      <td>0.718619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.564100</td>\n",
       "      <td>0.826817</td>\n",
       "      <td>0.718429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.819100</td>\n",
       "      <td>0.832208</td>\n",
       "      <td>0.714476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.688000</td>\n",
       "      <td>0.817808</td>\n",
       "      <td>0.719476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.695600</td>\n",
       "      <td>0.812985</td>\n",
       "      <td>0.724381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.552700</td>\n",
       "      <td>0.807601</td>\n",
       "      <td>0.721381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.789300</td>\n",
       "      <td>0.803206</td>\n",
       "      <td>0.724762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.728900</td>\n",
       "      <td>0.805086</td>\n",
       "      <td>0.726286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.584900</td>\n",
       "      <td>0.800563</td>\n",
       "      <td>0.731905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.461200</td>\n",
       "      <td>0.857237</td>\n",
       "      <td>0.722048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.415800</td>\n",
       "      <td>0.901684</td>\n",
       "      <td>0.717905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.887251</td>\n",
       "      <td>0.722905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.352500</td>\n",
       "      <td>0.869929</td>\n",
       "      <td>0.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.453400</td>\n",
       "      <td>0.868623</td>\n",
       "      <td>0.725619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.389100</td>\n",
       "      <td>0.863606</td>\n",
       "      <td>0.728238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.483400</td>\n",
       "      <td>0.882482</td>\n",
       "      <td>0.727714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.484300</td>\n",
       "      <td>0.871877</td>\n",
       "      <td>0.726810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.400600</td>\n",
       "      <td>0.876393</td>\n",
       "      <td>0.728857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.447700</td>\n",
       "      <td>0.873522</td>\n",
       "      <td>0.728952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15750, training_loss=0.6872419414823018, metrics={'train_runtime': 4639.6023, 'train_samples_per_second': 54.315, 'train_steps_per_second': 3.395, 'total_flos': 8346190261248000.0, 'train_loss': 0.6872419414823018, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T18:25:19.457164Z",
     "iopub.status.busy": "2025-06-05T18:25:19.456627Z",
     "iopub.status.idle": "2025-06-05T18:26:28.280311Z",
     "shell.execute_reply": "2025-06-05T18:26:28.279810Z",
     "shell.execute_reply.started": "2025-06-05T18:25:19.457140Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = trainer.predict(tokenized_datasets[\"test\"])  # or [\"validation\"]\n",
    "preds = predictions.predictions.argmax(axis=-1)\n",
    "labels = predictions.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T18:26:28.300684Z",
     "iopub.status.busy": "2025-06-05T18:26:28.300486Z",
     "iopub.status.idle": "2025-06-05T18:26:28.318145Z",
     "shell.execute_reply": "2025-06-05T18:26:28.317578Z",
     "shell.execute_reply.started": "2025-06-05T18:26:28.300669Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      3076\n",
      "           1       0.70      0.69      0.70      3016\n",
      "           2       0.91      0.91      0.91      2952\n",
      "           3       0.72      0.69      0.70      2951\n",
      "           4       0.73      0.73      0.73      3063\n",
      "           5       0.53      0.52      0.52      3013\n",
      "           6       0.75      0.78      0.76      2929\n",
      "\n",
      "    accuracy                           0.73     21000\n",
      "   macro avg       0.73      0.73      0.73     21000\n",
      "weighted avg       0.73      0.73      0.73     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T18:28:28.755196Z",
     "iopub.status.busy": "2025-06-05T18:28:28.754938Z",
     "iopub.status.idle": "2025-06-05T18:28:29.360302Z",
     "shell.execute_reply": "2025-06-05T18:28:29.359692Z",
     "shell.execute_reply.started": "2025-06-05T18:28:28.755179Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./my_model/tokenizer_config.json',\n",
       " './my_model/special_tokens_map.json',\n",
       " './my_model/vocab.txt',\n",
       " './my_model/added_tokens.json',\n",
       " './my_model/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./my_model\")\n",
    "tokenizer.save_pretrained(\"./my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T18:28:36.735874Z",
     "iopub.status.busy": "2025-06-05T18:28:36.735192Z",
     "iopub.status.idle": "2025-06-05T18:28:51.057153Z",
     "shell.execute_reply": "2025-06-05T18:28:51.056362Z",
     "shell.execute_reply.started": "2025-06-05T18:28:36.735851Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: my_model/ (stored 0%)\n",
      "  adding: my_model/tokenizer.json (deflated 71%)\n",
      "  adding: my_model/config.json (deflated 53%)\n",
      "  adding: my_model/special_tokens_map.json (deflated 42%)\n",
      "  adding: my_model/vocab.txt (deflated 53%)\n",
      "  adding: my_model/model.safetensors"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (deflated 8%)\n",
      "  adding: my_model/tokenizer_config.json (deflated 75%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r my_model.zip my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T18:29:40.762679Z",
     "iopub.status.busy": "2025-06-05T18:29:40.762186Z",
     "iopub.status.idle": "2025-06-05T18:29:40.767517Z",
     "shell.execute_reply": "2025-06-05T18:29:40.766820Z",
     "shell.execute_reply.started": "2025-06-05T18:29:40.762655Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='my_model.zip' target='_blank'>my_model.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/my_model.zip"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('my_model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T18:36:50.603770Z",
     "iopub.status.busy": "2025-06-05T18:36:50.603224Z",
     "iopub.status.idle": "2025-06-05T18:37:03.955983Z",
     "shell.execute_reply": "2025-06-05T18:37:03.955284Z",
     "shell.execute_reply.started": "2025-06-05T18:36:50.603741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/my_model.zip'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive('my_model', 'zip', '/kaggle/working/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T18:37:25.912749Z",
     "iopub.status.busy": "2025-06-05T18:37:25.912264Z",
     "iopub.status.idle": "2025-06-05T18:37:25.917631Z",
     "shell.execute_reply": "2025-06-05T18:37:25.916892Z",
     "shell.execute_reply.started": "2025-06-05T18:37:25.912730Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='my_model.zip' target='_blank'>my_model.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/my_model.zip"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'my_model.zip')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7591875,
     "sourceId": 12061639,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
